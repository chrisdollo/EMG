{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ApAYXdrk2pta"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat\n",
    "import os\n",
    "from feature_extraction import features_estimation\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot function\n",
    "#### Plots 2 different signals\n",
    "#### Used to show the difference between the base and resampled signals\n",
    "\n",
    "This is a helper function that can be used to plot our signals and check that a modification has been applied.\n",
    "It takes in the original signal and the modified one and plots both on the same axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to plot a graph\n",
    "def plot_signal_modification(time, original_signal, time1, new_signal):\n",
    "    \"\"\"\n",
    "    Function to plot 2 simple graph.\n",
    "\n",
    "    Parameters:\n",
    "    - time:             Duration of the signal in seconds\n",
    "    - original_signal:  Array containing the readings for the original signal\n",
    "    - new_signal:       Array containing the readings for the new signal\n",
    "    - time1:            Duration of the signal in seconds\n",
    "    \"\"\"\n",
    "\n",
    "    # Plotting the original EMG signal\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(time, original_signal, color='b', linewidth=2)\n",
    "    plt.plot(time1, new_signal, color='r', linewidth=1)\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"EMG Signal (mV)\")\n",
    "    plt.title(\"EMG Signal Over Time\")\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "    # time_resampled = np.linspace(0, time[-1], target_length)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing function\n",
    "#### Used to modify the length of the signal for one subject \n",
    "This function can be used to resize the the EMG signals for a specific subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniformize_data_subject(input_file_path, sub_num, target_length, output_dict = \"E:\\\\Chris\\\\EMG\\\\Data\\\\processed data\"):\n",
    "    \n",
    "\n",
    "    num_sensors = 24\n",
    "    sampling_rate = 5120\n",
    "\n",
    "    # Load the MATLAB file\n",
    "    mat_data = scipy.io.loadmat(input_file_path)\n",
    "    data = mat_data['processed_data']\n",
    "    set_of_all_gesture_by_subject = np.array(data)\n",
    "\n",
    "    gestures = set_of_all_gesture_by_subject.shape[1]\n",
    "    repetitions = set_of_all_gesture_by_subject.shape[0]\n",
    "\n",
    "\n",
    "    # we access all repetitions of the 7 types of hand gestures\n",
    "    for i in range(repetitions): # shape (28,)\n",
    "\n",
    "        # we access a specific gesture type\n",
    "        for j in range(gestures):\n",
    "\n",
    "            # hand_gesture_type contains the electrovolts reading of the 24 sensors placed on the subjects arms at the ith repetition of the jth hand gesture type\n",
    "            hand_gesture_type = set_of_all_gesture_by_subject[i,j]    # shape(....,24)\n",
    "            \n",
    "            # we check if the sampling length of the signals of this gesture matches the desired length\n",
    "            if hand_gesture_type.shape[0] != target_length:\n",
    "\n",
    "                # if it isn't we create a new array of the appropriate size\n",
    "                new_gesture = np.zeros((target_length, num_sensors))\n",
    "\n",
    "                # for all sensors we modify the expand the length of the gesture recorded\n",
    "                for k in range(num_sensors):\n",
    "                    sample_to_alter = hand_gesture_type[:,k]  # shape (..., 1)\n",
    "                    resampled_signal = signal.resample(sample_to_alter , target_length)\n",
    "                    new_gesture[:,k] = resampled_signal\n",
    "\n",
    "                    if i == 1 and j == 1 and k == 1:\n",
    "                        time = np.arange(len(sample_to_alter)) / sampling_rate\n",
    "                        time2 = np.arange(len(resampled_signal)) / sampling_rate\n",
    "                        plot_signal_modification(time, sample_to_alter, time2, resampled_signal)\n",
    "\n",
    "\n",
    "                    print( f\"converted subject {sub_num} repetition {repetitions} gestures {j} channel {k} \")\n",
    "                    \n",
    "                set_of_all_gesture_by_subject[i,j] = new_gesture\n",
    "\n",
    "   \n",
    "    output_data = {'processed_data': set_of_all_gesture_by_subject}\n",
    "    os.makedirs(output_dict, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    \n",
    "    output_path = os.path.join(output_dict, 'processed_gestures_subject'+ str(sub_num)+ '.mat')\n",
    "\n",
    "    # Save the file\n",
    "    savemat(output_path, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creator\n",
    "\n",
    "#### This function is used to create the dataset that will be used for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(num_of_subject = 0, empty_table_path = f\"/Users/chrisdollo/Documents/coding_projects/EMG/Matlab/gestureTable_clean_deep_learning.mat\" , output_dict=\"E:\\Chris\\EMG\\Data\\processed data\\combined_datasets\"):\n",
    "    \"\"\"\n",
    "    This function creates a matfile that contains hand gesture data from a given range of subjects\n",
    "    the data is formated as (x, 1500, 24) where x corresponds to the mnumber of subjects times 28\n",
    "    \"\"\"\n",
    "\n",
    "    # no 0,1,2,21,28,32,37,40,41,44,52\n",
    "\n",
    "    subject_row_map = {\n",
    "        3: (0, 28),\n",
    "        4: (28, 56),\n",
    "        5: (56, 84),\n",
    "        6: (84, 112),\n",
    "        7: (112, 140),\n",
    "        8: (140, 168),\n",
    "        9: (168, 196),\n",
    "        10: (196, 224),\n",
    "        11: (224, 252),\n",
    "        12: (252, 280),\n",
    "        13: (280, 308),\n",
    "        14: (308, 336),\n",
    "        15: (336, 364),\n",
    "        16: (364, 392),\n",
    "        17: (392, 420),\n",
    "        18: (420, 448),\n",
    "        19: (448, 476),\n",
    "        20: (476, 504),\n",
    "        22: (504, 532),\n",
    "        23: (532, 560),\n",
    "        24: (560, 588),\n",
    "    }\n",
    "\n",
    "\n",
    "    # load the matlab table\n",
    "    table = scipy.io.loadmat(empty_table_path)\n",
    "    cell_array = np.array(table['finalCellArray'])  # shape (84, 7) and each cell is (1500, 24)\n",
    "\n",
    "    for subject in range(1, num_of_subject):\n",
    "        \n",
    "        if subject not in [0,1,2,21,28,32,37,40,41,44,52]:\n",
    "            print(subject)\n",
    "            try:\n",
    "\n",
    "                # we load the hand gesture data from individual subject \n",
    "                file_path = f\"E:\\\\Chris\\\\EMG\\\\Data\\\\processed data\\\\1500\\\\processed_gestures_subject{subject}.mat\"\n",
    "                mat_file = scipy.io.loadmat(file_path)\n",
    "                cell_array_gesture = mat_file['processed_data']\n",
    "                cell_array_gesture = np.array(cell_array_gesture)           # contains the (28, 7)\n",
    "\n",
    "                \n",
    "\n",
    "                # we write the subject data to the appropriate rows and columns in our final table\n",
    "                cell_array[(subject_row_map[subject][0]):(subject_row_map[subject][1]), : ] = cell_array_gesture\n",
    "\n",
    "                print(f\"successfull for subject: {subject}\")\n",
    "\n",
    "            # we uniformize the number \n",
    "            except FileNotFoundError:\n",
    "                print(f\"failed  for subject: {subject}\")\n",
    "\n",
    "\n",
    "    # we save the new data to our final file \n",
    "    output_data = {'processed_data': cell_array}\n",
    "    os.makedirs(output_dict, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "        \n",
    "    output_path = os.path.join(output_dict, 'final_data_for_20_subject.mat')\n",
    "    savemat(output_path, output_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, table_path, subject_row_map, subject, sampling_rate, window_size, step_size):\n",
    "\n",
    "    # load the matlab table\n",
    "    table = scipy.io.loadmat(table_path)\n",
    "    cell_array = table['finalCellArray']  # shape (84, 7)\n",
    "\n",
    "    # Load the MATLAB file\n",
    "    mat_data = scipy.io.loadmat(file_path)\n",
    "    data = mat_data[\"processed_data\"]\n",
    "    set_of_all_gesture_by_subject = np.array(data)\n",
    "    \n",
    "    gestures = set_of_all_gesture_by_subject.shape[1]\n",
    "    repetitions = set_of_all_gesture_by_subject.shape[0]\n",
    "    sensors = (set_of_all_gesture_by_subject[0][0].shape)[1]\n",
    "\n",
    "    print(\"Number of gestures detected is: \", gestures, \"\\n number of repetitions is detected is: \", repetitions, \" \\nnumber of sensors detected is: \", sensors)\n",
    "\n",
    "    # Get the row range to write to\n",
    "    row_start, row_end = subject_row_map[subject]\n",
    "    row_index = row_start\n",
    "\n",
    "    ## acees the whole table \n",
    "    print(cell_array.shape)\n",
    "\n",
    "    # acccess\n",
    "    print(cell_array[0].shape)\n",
    "\n",
    "    # access a hand gesture\n",
    "    print(cell_array[0][0].shape)\n",
    "\n",
    "    # sensors are rows, features are columns\n",
    "\n",
    "    # access all features of a sensor\n",
    "    print(cell_array[0][0][0,:].shape)\n",
    "\n",
    "\n",
    "    print(row_start)\n",
    "\n",
    "    # all gestures types\n",
    "    for gesture_idx in range(gestures): # repeats 7 times\n",
    "        for repetition_idx in range(repetitions): # repeats 28 times\n",
    "\n",
    "            feature_cell = [[None for _ in range(18)] for _ in range(sensors)]\n",
    "\n",
    "            for sensor_idx in range(sensors): # repeats 24 times\n",
    "\n",
    "                # extract the 18 features \n",
    "                emg_features, features_names = features_estimation(set_of_all_gesture_by_subject[repetition_idx][gesture_idx][:,sensor_idx],  \n",
    "                                                                   \"Gesture \" + str(gesture_idx+1) + \" repetition \" + str(repetition_idx+1) + \n",
    "                                                                   \" channel \" + str(sensor_idx+1)  , sampling_rate, window_size, \n",
    "                                                                   step_size)\n",
    "\n",
    "                # Flatten and convert to list\n",
    "                emg_features = emg_features.to_numpy().flatten().tolist()\n",
    "                feature_cell[sensor_idx] = emg_features\n",
    "\n",
    "            # Store the 24 by 28 gesture\n",
    "            cell_array[row_index, gesture_idx] = np.array(feature_cell, dtype=object)\n",
    "            row_index += 1\n",
    "\n",
    "            print(\"Wrote for gesture: \", gesture_idx,\" repetition \", repetition_idx, \" this was at row \", row_index)\n",
    "\n",
    "        row_index = row_start\n",
    "            \n",
    "\n",
    "                \n",
    "                \n",
    "    # Save back to .mat file\n",
    "    scipy.io.savemat(table_path, {'finalCellArray': cell_array})\n",
    "    print(f\"âœ… Saved updated feature data for subject {subject}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call functions Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "successfull for subject: 3\n",
      "4\n",
      "successfull for subject: 4\n",
      "5\n",
      "successfull for subject: 5\n",
      "6\n",
      "successfull for subject: 6\n",
      "7\n",
      "successfull for subject: 7\n",
      "8\n",
      "successfull for subject: 8\n",
      "9\n",
      "successfull for subject: 9\n",
      "10\n",
      "successfull for subject: 10\n",
      "11\n",
      "successfull for subject: 11\n",
      "12\n",
      "successfull for subject: 12\n",
      "13\n",
      "successfull for subject: 13\n",
      "14\n",
      "successfull for subject: 14\n",
      "15\n",
      "successfull for subject: 15\n",
      "16\n",
      "successfull for subject: 16\n",
      "17\n",
      "successfull for subject: 17\n",
      "18\n",
      "successfull for subject: 18\n",
      "19\n",
      "successfull for subject: 19\n",
      "20\n",
      "successfull for subject: 20\n",
      "22\n",
      "successfull for subject: 22\n"
     ]
    }
   ],
   "source": [
    "create_dataset(num_of_subject = 23, empty_table_path = \"E:\\\\Chris\\\\EMG\\\\EMG\\\\Matlab\\\\gestureTable_clean_deep_learning_for_20_subject.mat\", output_dict=\"E:\\\\Chris\\\\EMG\\\\Data\\\\processed data\\\\combined_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow-gpu_1)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe50d63974df50d14597ca6e20df72aedc533c021a02b773358909844a0e40be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
